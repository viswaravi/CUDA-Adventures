# CUDA Challenge

## Overview
This repository contains a series of progressively advancing CUDA programming tasks designed to strengthen my understanding of GPU programming and optimization focused on Computer Vision and LLMs.

## Sections

### **1. CUDA Basics**
**Goal:** Refresh the CUDA fundamentals and implement basic kernels. Kernel profiling using NSight Compute and NSight Systems.

### **2. CUDA Performance Optimizations**
**Goal:** Deepen my understanding of memory access patterns and warp-level optimizations. implement optimized version of kernels and compare performance gains through profiling.

### **3. Computer Vision - Custom CUDA Kernels for Image Processing**
**Goal:** Implement custom kernels for image processing tasks.

### **4. Computer Vision - Optimized CNN Kernels (Project 4)**
**Goal:** Optimize the image processing kernels for key operations in Convolutional Neural Networks (CNNs), Integration with CUDA Graphs and benchmark the performance difference.

### **5. Fast Matrix Multiplication**
**Goal:** Optimize matrix multiplication using hardware-specific features. Utilize Tensor Cores. Test performance scaling.

### **6. Transformer Attention Optimization**
**Goal:** Develop and optimize kernels for softmax and self-attention mechanisms used in Transformer architectures.

### **7. Sparse Matrix Operations for LLM Efficiency**
**Goal:** Optimize sparse matrix operations, crucial for large language model (LLM) efficiency.

### **8. Model Quantization & TensorRT Optimization**
**Goal:** Optimize models for inference by applying quantization and leveraging TensorRT.

### **9. Optimizing GPT Model**
**Goal:** Apply all learned CUDA techniques to optimize a GPT-style model for inference and training efficiency. Transformer layers and custom KV-cache implementation.

### **10. Multi-GPU Training & NCCL Optimization (Project 8)**
**Goal:** Scale the  optimizations across multiple GPUs for training large models.
